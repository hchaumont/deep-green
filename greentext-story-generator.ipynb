{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfrom keras.models import Sequential\nfrom keras.callbacks import LambdaCallback, ModelCheckpoint\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport sys\nimport io","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Text processing\n\npath = '../input/green.txt' \nwith io.open(path, encoding='utf-8') as f:\n    text = f.read().lower()\nprint('corpus length:', len(text))\n\nchars = sorted(list(set(text)))\nprint('total chars:', len(chars))\nchar_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))\n\n# cut the text in semi-redundant sequences of maxlen characters\nmaxlen = 40\nstep = 3\nsentences = []\nnext_chars = []\nfor i in range(0, len(text) - maxlen, step):\n    sentences.append(text[i: i + maxlen])\n    next_chars.append(text[i + maxlen])\nprint('nb sequences:', len(sentences))\n\nprint('Vectorization...')\nx = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\ny = np.zeros((len(sentences), len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        x[i, t, char_indices[char]] = 1\n    y[i, char_indices[next_chars[i]]] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13b0bb596f88af2cb00919b168e5a07f0eccf69e"},"cell_type":"code","source":"# Single LSTM layer model - Not much dropout\nprint('Build model...')\nmodel_single = Sequential()\nmodel_single.add(LSTM(128, input_shape=(maxlen, len(chars))))\nmodel_single.add(Dropout(.3))\nmodel_single.add(Dense(len(chars), activation='softmax'))\nmodel_single.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4020628bd76a8c7f0528f528faec8c6d730b52e9"},"cell_type":"code","source":"# Two layer LSTM - More dropout.\nprint('Build model...')\nmodel_double = Sequential()\nmodel_double.add(LSTM(128, input_shape=(maxlen, len(chars)),return_sequences=True))\nmodel_double.add(Dropout(.5))\nmodel_double.add(LSTM(128))\nmodel_double.add(Dropout(.5))\nmodel_double.add(Dense(len(chars), activation='softmax'))\nmodel_double.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cdae9ca751cabb31bf74ab05e94ed966b95a84e"},"cell_type":"code","source":"models = {'single': model_single, 'double': model_double}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"588fd6528dafa99ed6cf0f7362402dd1d612aa41"},"cell_type":"code","source":"filepath_single = \"single_weights.hdf5\"\nfilepath_double= \"double_weights.hdf5\"\ncheckpoint_single = ModelCheckpoint(filepath_single, \n                             monitor='val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='min')\ncheckpoint_double = ModelCheckpoint(filepath_double, \n                             monitor='val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='min')\ncheckpoints= {'single': checkpoint_single, 'double': checkpoint_double}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddb2e4e9047d44b16d84e795f850e533e978d065"},"cell_type":"code","source":"# Text Generation Functions\n\ndef sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef generate_text(model):\n    start_index = random.randint(0, len(text) - maxlen - 1)\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\n        print('----- diversity:', diversity)\n\n        generated = ''\n        sentence = text[start_index: start_index + maxlen]\n        generated += sentence\n        print('----- Generating with seed: \"' + sentence + '\"')\n        sys.stdout.write(generated)\n\n        for i in range(400):\n            x_pred = np.zeros((1, maxlen, len(chars)))\n            for t, char in enumerate(sentence):\n                x_pred[0, t, char_indices[char]] = 1.\n\n            preds = model.predict(x_pred, verbose=0)[0]\n            next_index = sample(preds, diversity)\n            next_char = indices_char[next_index]\n\n            generated += next_char\n            sentence = sentence[1:] + next_char\n\n            sys.stdout.write(next_char)\n            sys.stdout.flush()\n        print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"387657316a86c898ccc8de48c833a48edb798654"},"cell_type":"code","source":"history = dict()\nfor name, model in models.items():\n    history[name] = model.fit(x, y,\n                              batch_size=2048,\n                              epochs=40,\n                              validation_split=.15,\n                              verbose=2,\n                              shuffle=False,\n                              callbacks=[checkpoints[name]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b07690c591a583b1ab640702bbb841a0f8f5336e"},"cell_type":"code","source":"for name in models.keys():\n    plt.plot(history[name].history['loss'])\n    plt.plot(history[name].history['val_loss'])\n    plt.title('Training History')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\nplt.legend(['train-single', 'val-single','train-double', 'val-double'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af70e9755a5b2597d993e5531c2e196abc4f16cb"},"cell_type":"code","source":"generate_text(model_single)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7487aa8db207dc72d4e83171b8698acfc7255d5"},"cell_type":"code","source":"generate_text(model_double)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}