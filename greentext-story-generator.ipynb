{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f09cf79adc16287a0149f5ff39c2ee2912aeccf9"
   },
   "source": [
    "# Generating text using 4chan greentext stories.\n",
    "\n",
    "I've scraped a bunch of greentext from the archives of 4chan's /r9k/ (Robot9001) and /fit/ (Fitness) boards. We'd like to train a char-RNN on this data to see what kind of text a neural network can generate.\n",
    "\n",
    "Given a sequence of text from /r9k/, we'd like to train the neural network to \"guess\" the most likely next character in the sequence. For example, if we were to feed in the sequence *>be m*, the RNN would output a probability distribution on characters where the most likely one is *e*.\n",
    "\n",
    "To turn the scraped text into data that can be used to train the network, we'll split the text into a collection of overlapping sequences of a fixed length. The idea is to feed in the characters of the sequence and then have the network try to guess the next character after the sequence. \n",
    "\n",
    "We one-hot encode the characters so that they can be fed to the network.\n",
    "\n",
    "The text processing steps are based on the char-RNN example in the keras examples and the network architecture is loosly inspired by the many char-RNN architectures out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "8ab3892aac8509c468197f4dbe0f8297a0e8a4ad"
   },
   "outputs": [],
   "source": [
    "# Turn the corpus into a collection of labelled training examples.\n",
    "\n",
    "def process_text(path, maxlen, step):\n",
    "    with io.open(path, encoding='utf-8') as f:\n",
    "        text = f.read().lower()\n",
    "    print('Corpus length:', len(text))\n",
    "    \n",
    "    chars = sorted(list(set(text)))\n",
    "    print('Distinct characters:', len(chars))\n",
    "    print(chars)\n",
    "    \n",
    "    # Maps to convert characters to indices and back. \n",
    "    char_indices = dict((c,i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i,c) for i, c in enumerate(chars))\n",
    "    \n",
    "    # We'll create labelled training data by feeding in the sequence of characters in\n",
    "    # a chunk of the text of size maxlen. The next character in the text will be the label.\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    print('Number of sequences:', len(sentences))\n",
    "    \n",
    "    # One-hot encode the characters\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
    "    y = np.zeros((len(sentences),len(chars)), dtype = np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for j, char in enumerate(sentence):\n",
    "            X[i, j, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "    return char_indices, indices_char, X, y, text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9917e4e75ac9018339b349cf9ed0eebcd21e50f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 2603064\n",
      "Distinct characters: 71\n",
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '’', '“', '”']\n",
      "Number of sequences: 867675\n"
     ]
    }
   ],
   "source": [
    "path_r9k = '../input/green.txt'\n",
    "#path_fit = '../input/fit_green.txt'\n",
    "\n",
    "r9k_char_indices, r9k_indices_char, X_r9k, y_r9k, text_r9k = process_text(path_r9k, 40, 3)\n",
    "#fit_char_indices, fit_indices_char, X_fit, y_fit, text_fit = process_text(path_fit, 40, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "093e1ef4eb6d0f43fb074a9cdea6040be5f2cee7"
   },
   "outputs": [],
   "source": [
    "# Functions to generate text\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_text(model, maxlen, text, char_indices, indices_char, temperature, length):\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, maxlen, len(char_indices)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f908679aadab1f7076a96894ae4b9097c1b15520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 256)           335872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 256)           1024      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 71)                9159      \n",
      "=================================================================\n",
      "Total params: 543,687\n",
      "Trainable params: 542,919\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Basic model: 2 LSTM layers\n",
    "SEQLEN, CHARS = 40, len(r9k_char_indices)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(SEQLEN, CHARS), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(CHARS, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.004))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "241637aedbbd7882be1caa6a6a1ca99784097780"
   },
   "source": [
    "### We'll keep track of the state of the model with the lowest training loss and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7f40ca73908881bfd3fe487a180aed977e2b7936"
   },
   "outputs": [],
   "source": [
    "r9k_weights_best_val = 'r9k_best_val_weights.hdf5'\n",
    "r9k_weights_best_loss = 'r9k_best_loss_weights.hdf5'\n",
    "checkpoint_val = ModelCheckpoint(filepath=r9k_weights_best_val,\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='min')\n",
    "checkpoint_loss = ModelCheckpoint(filepath=r9k_weights_best_loss,\n",
    "                                 monitor='loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7c8880b652fadafba1ed7779a10471274eaa08b"
   },
   "source": [
    "### Train for 40 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "63bb61b09f70f3e87f50ddbd5e83be1968dfecda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 780907 samples, validate on 86768 samples\n",
      "Epoch 1/40\n",
      " - 193s - loss: 2.0424 - val_loss: 2.2265\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.22646, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.04240, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 2/40\n",
      " - 188s - loss: 1.6939 - val_loss: 1.7364\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.22646 to 1.73640, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 2.04240 to 1.69394, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 3/40\n",
      " - 188s - loss: 1.6043 - val_loss: 1.6554\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.73640 to 1.65538, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00003: loss improved from 1.69394 to 1.60430, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 4/40\n",
      " - 188s - loss: 1.5508 - val_loss: 1.6363\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.65538 to 1.63630, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00004: loss improved from 1.60430 to 1.55084, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 5/40\n",
      " - 188s - loss: 1.5126 - val_loss: 1.6189\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.63630 to 1.61887, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00005: loss improved from 1.55084 to 1.51264, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 6/40\n",
      " - 188s - loss: 1.4818 - val_loss: 1.6167\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.61887 to 1.61669, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 1.51264 to 1.48179, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 7/40\n",
      " - 188s - loss: 1.4556 - val_loss: 1.5803\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.61669 to 1.58027, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00007: loss improved from 1.48179 to 1.45563, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 8/40\n",
      " - 188s - loss: 1.4320 - val_loss: 1.5547\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.58027 to 1.55474, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00008: loss improved from 1.45563 to 1.43202, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 9/40\n",
      " - 188s - loss: 1.4103 - val_loss: 1.5533\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.55474 to 1.55328, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00009: loss improved from 1.43202 to 1.41030, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 10/40\n",
      " - 188s - loss: 1.3901 - val_loss: 1.5506\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.55328 to 1.55060, saving model to r9k_best_val_weights.hdf5\n",
      "\n",
      "Epoch 00010: loss improved from 1.41030 to 1.39011, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 11/40\n",
      " - 188s - loss: 1.3706 - val_loss: 1.5572\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00011: loss improved from 1.39011 to 1.37064, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 12/40\n",
      " - 188s - loss: 1.3520 - val_loss: 1.5590\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00012: loss improved from 1.37064 to 1.35203, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 13/40\n",
      " - 188s - loss: 1.3350 - val_loss: 1.5641\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00013: loss improved from 1.35203 to 1.33502, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 14/40\n",
      " - 188s - loss: 1.3196 - val_loss: 1.5578\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00014: loss improved from 1.33502 to 1.31956, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 15/40\n",
      " - 189s - loss: 1.3049 - val_loss: 1.5574\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00015: loss improved from 1.31956 to 1.30490, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 16/40\n",
      " - 189s - loss: 1.2896 - val_loss: 1.5570\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00016: loss improved from 1.30490 to 1.28965, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 17/40\n",
      " - 188s - loss: 1.2754 - val_loss: 1.5565\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00017: loss improved from 1.28965 to 1.27536, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 18/40\n",
      " - 189s - loss: 1.2619 - val_loss: 1.5613\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00018: loss improved from 1.27536 to 1.26191, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 19/40\n",
      " - 189s - loss: 1.2479 - val_loss: 1.5636\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00019: loss improved from 1.26191 to 1.24794, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 20/40\n",
      " - 189s - loss: 1.2370 - val_loss: 1.5633\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00020: loss improved from 1.24794 to 1.23700, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 21/40\n",
      " - 189s - loss: 1.2258 - val_loss: 1.5617\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00021: loss improved from 1.23700 to 1.22583, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 22/40\n",
      " - 188s - loss: 1.2154 - val_loss: 1.5732\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00022: loss improved from 1.22583 to 1.21539, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 23/40\n",
      " - 189s - loss: 1.2041 - val_loss: 1.5785\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00023: loss improved from 1.21539 to 1.20412, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 24/40\n",
      " - 188s - loss: 1.1942 - val_loss: 1.5880\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00024: loss improved from 1.20412 to 1.19425, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 25/40\n",
      " - 189s - loss: 1.1848 - val_loss: 1.6023\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00025: loss improved from 1.19425 to 1.18477, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 26/40\n",
      " - 189s - loss: 1.1767 - val_loss: 1.6046\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00026: loss improved from 1.18477 to 1.17673, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 27/40\n",
      " - 189s - loss: 1.1668 - val_loss: 1.6081\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00027: loss improved from 1.17673 to 1.16684, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 28/40\n",
      " - 189s - loss: 1.1587 - val_loss: 1.6184\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00028: loss improved from 1.16684 to 1.15874, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 29/40\n",
      " - 189s - loss: 1.1515 - val_loss: 1.6206\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00029: loss improved from 1.15874 to 1.15154, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 30/40\n",
      " - 189s - loss: 1.1433 - val_loss: 1.6264\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00030: loss improved from 1.15154 to 1.14326, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 31/40\n",
      " - 189s - loss: 1.1360 - val_loss: 1.6355\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00031: loss improved from 1.14326 to 1.13597, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 32/40\n",
      " - 189s - loss: 1.1284 - val_loss: 1.6494\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00032: loss improved from 1.13597 to 1.12836, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 33/40\n",
      " - 189s - loss: 1.1220 - val_loss: 1.6581\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00033: loss improved from 1.12836 to 1.12199, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 34/40\n",
      " - 189s - loss: 1.1154 - val_loss: 1.6656\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00034: loss improved from 1.12199 to 1.11537, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 35/40\n",
      " - 189s - loss: 1.1089 - val_loss: 1.6660\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00035: loss improved from 1.11537 to 1.10892, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 36/40\n",
      " - 189s - loss: 1.1039 - val_loss: 1.6706\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00036: loss improved from 1.10892 to 1.10386, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 37/40\n",
      " - 189s - loss: 1.0998 - val_loss: 1.6606\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00037: loss improved from 1.10386 to 1.09982, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 38/40\n",
      " - 189s - loss: 1.0955 - val_loss: 1.6709\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00038: loss improved from 1.09982 to 1.09549, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 39/40\n",
      " - 189s - loss: 1.0876 - val_loss: 1.6784\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00039: loss improved from 1.09549 to 1.08758, saving model to r9k_best_loss_weights.hdf5\n",
      "Epoch 40/40\n",
      " - 189s - loss: 1.0804 - val_loss: 1.6907\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.55060\n",
      "\n",
      "Epoch 00040: loss improved from 1.08758 to 1.08039, saving model to r9k_best_loss_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "history_r9k = model.fit(X_r9k, y_r9k,\n",
    "                        batch_size=2048,\n",
    "                        epochs=40,\n",
    "                        validation_split=.1,\n",
    "                        verbose=2,\n",
    "                        shuffle=False,\n",
    "                        callbacks=[checkpoint_val, checkpoint_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d7faa614d3567350a22accc34ae26aefc8419bc"
   },
   "source": [
    "### Let's see how training went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "90f272774c74f38f7996a4767769e050fb2cb08a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_r9k.history['loss'])\n",
    "plt.plot(history_r9k.history['val_loss'])\n",
    "plt.title('Training History')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbda9f2ec8fabb473ceef0eea87056587ca724b4"
   },
   "source": [
    "### Sample text after the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "f2830dc12616b8ec12f7f3083c072a6d0d96193e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"ners\n",
      ">get out\n",
      ">didnt notice car that was\"\n",
      "ners\n",
      ">get out\n",
      ">didnt notice car that was a special but if yes\n",
      ">she is expenside them about there has a female and says \"you have to bury orbidished or husband\" as shert to school mics\n",
      "\n",
      ">tell me her walls shy\n",
      "\n",
      ">be me\n",
      ">be online fantasien\n",
      ">grab my classmates\n",
      ">masturbodd smokes shit still goals me for a cup back cheesbagning, anon: trapped\n",
      ">turns of cheap me like to college\n",
      ">notward all less texts\n",
      ">how instantly weighs eaving?\n",
      ">what do you text my paped\n",
      ">going to dring\n",
      ">news from my eviceface\n",
      ">hes again sfully deep up the familteks\n",
      ">drugs, crotted to my bed rigges to get an interestment instantly\n",
      ">i'm not\n",
      ">idencitive flesbans\n",
      ">husbandojo's animal circummists she was his taxi\n",
      "\n",
      ">i decidy \n",
      ">he's directly want your field her my roommate girls\n",
      ">we ranagrancingle for on hard\n",
      ">listening to a cunt for a word but launch and enter close\n",
      ">will can't try to clean date numbers\n",
      ">nonarly populary sometimes used one the united and why?\n",
      ">would you like your parents isn't apologin reaction\n",
      ">can't even have a few years of my grand for and being n\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('end_weights.hd5')\n",
    "generate_text(model, SEQLEN, text_r9k, r9k_char_indices, r9k_indices_char, 1.0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "af4cb1e565250451b7b848a28c2ebd9ccc26fb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"ays you're a bad influence\"\n",
      ">at this poi\"\n",
      "ays you're a bad influence\"\n",
      ">at this point i still there are day and i just got into shaft joins white are is flirting of times as a what bicker died\n",
      ">move towers unbelsting from her skills\n",
      ">eyebrown shore-lien during feed unist never mention hid, able and spent a chin dorm\n",
      ">in come over\n",
      "\n",
      ">19\n",
      ">grand schools builty and end up history of them not be drunk. rude to feel not done still the centrestism\n",
      ">her jot and cant remember that her\n",
      ">fuckyple to kill all alone\n",
      ">i just wanted about 5 years ago\n",
      ">start dating behind a job and meme up in the ecasuage their mix ontentially gives me the shower\n",
      ">the terrorone my health must have two only asigns to class and then i was to plsy\n",
      "> fembot and we never had\n",
      ">come with passes and tell him in cold\n",
      ">sorry weighen don't hear her warm\n",
      ">angustiated and pick it all the djaning and passion.png\n",
      ">be me\n",
      ">tells me i'm a gay punchanged with incels\n",
      ">''in a change talk \n",
      ">start getting back to a day and all obseas\n",
      ">muschless everything with a feet her\n",
      ">tell her to arriffi-hting to me\n",
      ">be me\n",
      ">170 \n",
      ">text \n"
     ]
    }
   ],
   "source": [
    "# With a slightly lower temperature.\n",
    "generate_text(model, SEQLEN, text_r9k, r9k_char_indices, r9k_indices_char, 0.8, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad02d3e0144ef0a5f681ec5a26358eecca7dd37c"
   },
   "source": [
    "### Sample text from model with best training loss\n",
    "Is the generated text the best when the model starts to over-train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "519822fd4da8f496f6e091196153a929c85e5071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \", 2009\n",
      ">this actually happened\n",
      ">pic unre\"\n",
      ", 2009\n",
      ">this actually happened\n",
      ">pic unrelasts and criminally untally ass about anyone on 4chan\n",
      "\n",
      ">car?\n",
      ">do you know and probably leave\n",
      ">can fuck closed\n",
      ">just hair colon to to my cute but never have been do in the people\n",
      ">indiet\n",
      ">there's a teacher\n",
      ">she fell in longer how things you've no one never if i'm tench in any\n",
      ">mfw\n",
      "\n",
      ">a without anxious in the villa, shit\n",
      ">learn an alcoholic and single dumpsying of tesk them beers as i uched it\n",
      ">i'm sonance at her about ago get a runs\n",
      ">cant aut friends like just kisses me to like whats working is an adult dump't\n",
      ">he feel walks up voice and deserves arguing\n",
      ">go to old friend > o been almost every day\n",
      ">soberal another place of bad.exv\n",
      ">180m svicingly\n",
      ">neaton your sexual inline classmates and no\n",
      ">after i was we starts but if i would nicen\n",
      ">shes be cithis aren't level in sounds\n",
      ">tells me she is all the intense around with me\n",
      ">after the probably not having any kind whats anongreeses than aifu\n",
      ">don't want to tescons\n",
      "\n",
      ">i didn't want to give years ugly\n",
      ">shit terred\n",
      ">another skus why is super seco\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(r9k_weights_best_loss)\n",
    "generate_text(model, SEQLEN, text_r9k, r9k_char_indices, r9k_indices_char, 1.0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "47f85a987b74d34cb9a406b6d59b81af02f5a95c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"ch morning?\n",
      ">what excites you?\n",
      ">what are\"\n",
      "ch morning?\n",
      ">what excites you?\n",
      ">what areasound blood cashies, and rejected and play happened\n",
      ">see up away from her riding her was discussion in bathroom \n",
      ">built short working feminate slaves\n",
      ">get numbers\n",
      ">help of this rest of\n",
      ">she text her out of the tests fealth of, last year\n",
      ">sitting in a stream of them\n",
      "\n",
      ">jecked and finally assume shit\n",
      ">feels\n",
      ">the fucking weeks\n",
      ">quiet shes backed out of fress, he says she is going to me, she took me to usa car and all starts can shit and finally enjoy the middle of girlfriend of second, where i am enter humans and piss in the quathing again\n",
      ">shes very chees \n",
      ">get seutes\n",
      ">religious to make a girl as living bitch hands less an all me\n",
      "\n",
      ">mfw i can't ghosting me\n",
      ">in a bit credit for all over person intellectional decayed and and went to ask me on teich\n",
      ">still have a family\n",
      ">she wants to get to a nevitading because its are you pussy zuzi\n",
      ">le rest of the class\n",
      ">i decide to go to enugly grand\n",
      ">be talking about cheespear\n",
      ">she should screens as hatting now\n",
      ">graduated scream to share her trues)\n",
      ">some\n"
     ]
    }
   ],
   "source": [
    "generate_text(model, SEQLEN, text_r9k, r9k_char_indices, r9k_indices_char, 0.8, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ed440d0b8fd252b8c6749da3704dac70efd21c5"
   },
   "source": [
    "### Sample text from model with best validation loss\n",
    "Or is performance better when the validation loss isn't as high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4bcb4dda07611ebf70c8f9343b33d102a9d15d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"cade fighters lately\n",
      ">conversations abou\"\n",
      "cade fighters lately\n",
      ">conversations about your away carass\n",
      ">xand pain swing from her cuse to talking about literally virginy\n",
      ">prisonated left\n",
      ">spised off\n",
      ">i wast of shit stronic\n",
      ">it tuman stranged treats\n",
      ">suicid for in\n",
      ">she let uses them or stop for fear of shuhh ri grace\n",
      ">you are car\n",
      ">for a personal anxiety ev\" aluce is team\n",
      "\n",
      ">she dirtlate school\n",
      ">i reals the bathroom\n",
      ">asks me up, but i don't know what is fucking\n",
      ">nonwowh...\n",
      ">delive me is her\n",
      ">she were me i was\n",
      ">bropoling gain\n",
      ">have aglet schedul where i really in and she does the shit\n",
      ">walk your confused in the strun with shed one of the eause\n",
      "\n",
      ">stopping campossed traple your waifu my face\n",
      ">she because her when you believe you just rote off\n",
      ">a find after she has delusing chese main she's 12-years-hag and points or saying small deal while keep lince\n",
      "\n",
      ">have do yur guy\n",
      ">shown easy as \"humoriable disgusted of me of the hours\n",
      "\n",
      ">i'm what that her more\n",
      ">one word couldn't still never there\n",
      ">girls - the super there when she like. she has a autistic what is improves a chourca\n",
      ">kippo\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(r9k_weights_best_val)\n",
    "generate_text(model, SEQLEN, text_r9k, r9k_char_indices, r9k_indices_char, 1.0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "54a2a1adad760ffd9a2be945acc0fe95da400431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"owave things for if it isn't written on \"\n",
      "owave things for if it isn't written on the easien way\n",
      ">posting after i was an interactions something it's a while she has she wasn i fairs she lets flaching twice and i only because i stop school in all of the big plash from my run who favorite material she random medical class on loxing\n",
      ">noticer\n",
      ">turn around 14 to half of comfy?\n",
      ">where were her anyone and because you broke her and have no off\n",
      ">sheld turned me to close of my back ar and she's rations of the same anyways\n",
      ">but children is you look are in cool user is a long has a while mom\n",
      ">i'm i start anything, she's virgin\n",
      ">no cray\n",
      ">get all over the hours\n",
      ">we all your morner, white\n",
      ">she is, as a lot\n",
      "\n",
      ">was apor than anything\"\n",
      ">i have a fror the beginnt i there she's fast of the and leging about any femboye\n",
      ">twontable she was the only the dirtened resterpour today aunt in the strengips\n",
      "\n",
      ">be me\n",
      ">fine\"\n",
      ">we're as no men in a class!?\n",
      ">what is your waifu's of these feeling until use they are you are put in from my door\n",
      ">\"targing applying to stopgery for her\n",
      ">i was a with a time de\n"
     ]
    }
   ],
   "source": [
    "generate_text(model, SEQLEN, text_r9k, r9k_char_indices, r9k_indices_char, 0.8, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
